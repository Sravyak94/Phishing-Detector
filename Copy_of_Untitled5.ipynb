{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIFNKm5njGo0DGH2CsH1sZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sravyak94/Phishing-Detector/blob/main/Copy_of_Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_91WhKDLis7"
      },
      "outputs": [],
      "source": [
        "pip install gretel-synthetics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from gretel_synthetics.train import train_rnn\n",
        "\n",
        "from gretel_synthetics.config import LocalConfig\n",
        "\n",
        "from gretel_synthetics.generate import generate_text"
      ],
      "metadata": {
        "id": "PkhrpwfbLr7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LocalConfig(\n",
        "\n",
        "   max_line_len=2048,   # the max line length for input training data\n",
        "\n",
        "   vocab_size=20000,    # tokenizer model vocabulary size\n",
        "\n",
        "   field_delimiter= ',' , # specify if the training text is structured, else “None“\n",
        "\n",
        "   overwrite=True,      # overwrite previously trained model checkpoints\n",
        "\n",
        "   checkpoint_dir=(Path.cwd() / \"checkpoints\").as_posix(),\n",
        "\n",
        "   input_data_path='output.csv',  # filepath or S3,\n",
        "\n",
        "   epochs= 200\n",
        ")"
      ],
      "metadata": {
        "id": "syHwiApKLwEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rnn(config)"
      ],
      "metadata": {
        "id": "B7Mb-NEDNmpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f375cce-8574-4d19-c15d-1187020d3c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-16 17:12:31,054 : MainThread : INFO : Loading SentencePieceTokenizerTrainer\n",
            "2022-03-16 17:12:31,056 : MainThread : INFO : Loading input data from output.csv\n",
            "2022-03-16 17:12:31,067 : MainThread : INFO : Training SentencePiece tokenizer\n",
            "2022-03-16 17:12:31,345 : MainThread : INFO : Loading tokenizer from: m.model\n",
            "2022-03-16 17:12:31,356 : MainThread : INFO : Tokenizer model vocabulary size: 1371 tokens\n",
            "2022-03-16 17:12:31,358 : MainThread : INFO : Mapping first line of training data\n",
            "\n",
            "'18.66<d>18.82<d>18.05<d>18.25<d>18.69<d>19.5<d>21.03<d>20.67<d>20.25<d>19.45<d>17.33<d>16.53<d>15.73<d>15.2<d>14.17<d>13.89<d>14.71<d>16.47<d>19.01<d>18.69<d>18.47<d>16.92<d>15.1<d>14.79<n>'\n",
            " ---- sample tokens mapped to pieces ---- > \n",
            "▁, 18., 66, <d>, 18., 8, 2, <d>, 18, ., 0, 5, <d>, 1, 8., 25, <d>, 1, 8, ., 69, <d>, 19, ., 5, <d>, 21.0, 3, <d>, 20, .6, 7, <d>, 20, .2, 5, <d>, 1, 9.4, 5, <d>, 1, 7, ., 3, 3, <d>, 16, .5, 3, <d>, 15, ., 73, <d>, 15, .2, <d>, 1, 4.1, 7, <d>, 13., 89, <d>, 14, ., 71, <d>, 16.4, 7, <d>, 19, ., 01, <d>, 1, 8., 6, 9, <d>, 18., 4, 7, <d>, 1, 6., 92, <d>, 15.1, <d>, 14., 79, <n>\n",
            "\n",
            "2022-03-16 17:12:31,360 : MainThread : INFO : Mapping first line of training data\n",
            "\n",
            "'18.66<d>18.82<d>18.05<d>18.25<d>18.69<d>19.5<d>21.03<d>20.67<d>20.25<d>19.45<d>17.33<d>16.53<d>15.73<d>15.2<d>14.17<d>13.89<d>14.71<d>16.47<d>19.01<d>18.69<d>18.47<d>16.92<d>15.1<d>14.79<n>'\n",
            " ---- sample tokens mapped to int ---- > \n",
            "694, 10, 4, 113, 6, 4, 123, 11, 4, 238, 11, 4, 91, 13, 4, 102, 4, 107, 8, 4, 129, 12, 4, 242, 11, 4, 146, 11, 4, 276, 8, 4, 127, 8, 4, 207, 8, 4, 385, 4, 45, 28, 4, 301, 13, 4, 250, 7, 4, 202, 12, 4, 121, 7, 4, 91, 13, 4, 178, 12, 4, 159, 6, 4, 337, 4, 250, 13, 3\n",
            "\n",
            "2022-03-16 17:12:31,390 : MainThread : WARNING : ***** GPU not found, CPU will be used instead! *****\n",
            "2022-03-16 17:12:31,394 : MainThread : INFO : Tokenizing input data\n",
            "100%|██████████| 1443/1443 [00:00<00:00, 30140.44it/s]\n",
            "2022-03-16 17:12:31,453 : MainThread : INFO : Shuffling input data\n",
            "2022-03-16 17:12:31,778 : MainThread : INFO : Creating validation dataset\n",
            "2022-03-16 17:12:31,849 : MainThread : INFO : Creating training dataset\n",
            "2022-03-16 17:12:31,899 : MainThread : INFO : Initializing synthetic model\n",
            "2022-03-16 17:12:32,519 : MainThread : INFO : Using keras.optimizers.RMSprop optimizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           350976    \n",
            "                                                                 \n",
            " dropout (Dropout)           (64, None, 256)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 256)           525312    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (64, None, 256)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 256)           525312    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (64, None, 256)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 1371)          352347    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,753,947\n",
            "Trainable params: 1,753,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "12/12 [==============================] - 27s 2s/step - loss: 5.4543 - accuracy: 0.2328 - val_loss: 4.3656 - val_accuracy: 0.3252\n",
            "Epoch 2/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 4.3729 - accuracy: 0.3216 - val_loss: 4.3564 - val_accuracy: 0.3243\n",
            "Epoch 3/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 4.3584 - accuracy: 0.3240 - val_loss: 4.3436 - val_accuracy: 0.3251\n",
            "Epoch 4/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 4.3514 - accuracy: 0.3246 - val_loss: 4.3186 - val_accuracy: 0.3256\n",
            "Epoch 5/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 4.3138 - accuracy: 0.3247 - val_loss: 4.3003 - val_accuracy: 0.3233\n",
            "Epoch 6/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 4.2508 - accuracy: 0.3246 - val_loss: 4.1834 - val_accuracy: 0.3237\n",
            "Epoch 7/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.7140 - accuracy: 0.3129 - val_loss: 3.2990 - val_accuracy: 0.3174\n",
            "Epoch 8/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.2293 - accuracy: 0.3268 - val_loss: 3.1814 - val_accuracy: 0.3286\n",
            "Epoch 9/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.1741 - accuracy: 0.3320 - val_loss: 3.0988 - val_accuracy: 0.3339\n",
            "Epoch 10/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.1094 - accuracy: 0.3353 - val_loss: 3.0627 - val_accuracy: 0.3322\n",
            "Epoch 11/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.0469 - accuracy: 0.3380 - val_loss: 3.0232 - val_accuracy: 0.3393\n",
            "Epoch 12/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.9848 - accuracy: 0.3396 - val_loss: 2.8860 - val_accuracy: 0.3452\n",
            "Epoch 13/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.9022 - accuracy: 0.3428 - val_loss: 2.8279 - val_accuracy: 0.3470\n",
            "Epoch 14/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.8398 - accuracy: 0.3447 - val_loss: 2.8574 - val_accuracy: 0.3464\n",
            "Epoch 15/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.8168 - accuracy: 0.3434 - val_loss: 2.7225 - val_accuracy: 0.3494\n",
            "Epoch 16/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.7382 - accuracy: 0.3477 - val_loss: 2.6997 - val_accuracy: 0.3509\n",
            "Epoch 17/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.6900 - accuracy: 0.3474 - val_loss: 2.6463 - val_accuracy: 0.3503\n",
            "Epoch 18/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 2.6544 - accuracy: 0.3482 - val_loss: 2.6023 - val_accuracy: 0.3481\n",
            "Epoch 19/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.6155 - accuracy: 0.3501 - val_loss: 2.5328 - val_accuracy: 0.3529\n",
            "Epoch 20/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.5614 - accuracy: 0.3513 - val_loss: 2.4898 - val_accuracy: 0.3567\n",
            "Epoch 21/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.5291 - accuracy: 0.3503 - val_loss: 2.4845 - val_accuracy: 0.3565\n",
            "Epoch 22/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.5066 - accuracy: 0.3518 - val_loss: 2.4192 - val_accuracy: 0.3553\n",
            "Epoch 23/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4835 - accuracy: 0.3519 - val_loss: 2.4298 - val_accuracy: 0.3547\n",
            "Epoch 24/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4715 - accuracy: 0.3529 - val_loss: 2.4078 - val_accuracy: 0.3573\n",
            "Epoch 25/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4523 - accuracy: 0.3553 - val_loss: 2.3859 - val_accuracy: 0.3574\n",
            "Epoch 26/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4427 - accuracy: 0.3561 - val_loss: 2.3817 - val_accuracy: 0.3616\n",
            "Epoch 27/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4289 - accuracy: 0.3561 - val_loss: 2.3852 - val_accuracy: 0.3598\n",
            "Epoch 28/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4223 - accuracy: 0.3587 - val_loss: 2.3745 - val_accuracy: 0.3623\n",
            "Epoch 29/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4105 - accuracy: 0.3576 - val_loss: 2.3284 - val_accuracy: 0.3657\n",
            "Epoch 30/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.4039 - accuracy: 0.3581 - val_loss: 2.3565 - val_accuracy: 0.3608\n",
            "Epoch 31/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3932 - accuracy: 0.3587 - val_loss: 2.3308 - val_accuracy: 0.3669\n",
            "Epoch 32/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3821 - accuracy: 0.3599 - val_loss: 2.3197 - val_accuracy: 0.3702\n",
            "Epoch 33/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3819 - accuracy: 0.3598 - val_loss: 2.3069 - val_accuracy: 0.3696\n",
            "Epoch 34/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3768 - accuracy: 0.3597 - val_loss: 2.2950 - val_accuracy: 0.3676\n",
            "Epoch 35/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3530 - accuracy: 0.3642 - val_loss: 2.2954 - val_accuracy: 0.3717\n",
            "Epoch 36/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3491 - accuracy: 0.3641 - val_loss: 2.2990 - val_accuracy: 0.3715\n",
            "Epoch 37/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3434 - accuracy: 0.3641 - val_loss: 2.3157 - val_accuracy: 0.3734\n",
            "Epoch 38/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3380 - accuracy: 0.3659 - val_loss: 2.2587 - val_accuracy: 0.3726\n",
            "Epoch 39/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3366 - accuracy: 0.3658 - val_loss: 2.2628 - val_accuracy: 0.3748\n",
            "Epoch 40/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3217 - accuracy: 0.3671 - val_loss: 2.2803 - val_accuracy: 0.3717\n",
            "Epoch 41/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3199 - accuracy: 0.3678 - val_loss: 2.2788 - val_accuracy: 0.3778\n",
            "Epoch 42/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3042 - accuracy: 0.3707 - val_loss: 2.2180 - val_accuracy: 0.3812\n",
            "Epoch 43/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3031 - accuracy: 0.3719 - val_loss: 2.2282 - val_accuracy: 0.3794\n",
            "Epoch 44/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3002 - accuracy: 0.3724 - val_loss: 2.2250 - val_accuracy: 0.3805\n",
            "Epoch 45/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2863 - accuracy: 0.3728 - val_loss: 2.2143 - val_accuracy: 0.3842\n",
            "Epoch 46/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2856 - accuracy: 0.3728 - val_loss: 2.2024 - val_accuracy: 0.3926\n",
            "Epoch 47/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2783 - accuracy: 0.3739 - val_loss: 2.2008 - val_accuracy: 0.3921\n",
            "Epoch 48/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2675 - accuracy: 0.3768 - val_loss: 2.1964 - val_accuracy: 0.3839\n",
            "Epoch 49/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2651 - accuracy: 0.3756 - val_loss: 2.2005 - val_accuracy: 0.3924\n",
            "Epoch 50/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2614 - accuracy: 0.3764 - val_loss: 2.1778 - val_accuracy: 0.3909\n",
            "Epoch 51/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2512 - accuracy: 0.3801 - val_loss: 2.1622 - val_accuracy: 0.3976\n",
            "Epoch 52/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2360 - accuracy: 0.3782 - val_loss: 2.1627 - val_accuracy: 0.4006\n",
            "Epoch 53/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2300 - accuracy: 0.3823 - val_loss: 2.1588 - val_accuracy: 0.4007\n",
            "Epoch 54/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2319 - accuracy: 0.3828 - val_loss: 2.1504 - val_accuracy: 0.3989\n",
            "Epoch 55/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2182 - accuracy: 0.3870 - val_loss: 2.1202 - val_accuracy: 0.4048\n",
            "Epoch 56/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2240 - accuracy: 0.3829 - val_loss: 2.1308 - val_accuracy: 0.4080\n",
            "Epoch 57/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2194 - accuracy: 0.3861 - val_loss: 2.1203 - val_accuracy: 0.4001\n",
            "Epoch 58/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2019 - accuracy: 0.3873 - val_loss: 2.1034 - val_accuracy: 0.4090\n",
            "Epoch 59/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1941 - accuracy: 0.3894 - val_loss: 2.1003 - val_accuracy: 0.4098\n",
            "Epoch 60/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1894 - accuracy: 0.3922 - val_loss: 2.1048 - val_accuracy: 0.4202\n",
            "Epoch 61/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1798 - accuracy: 0.3914 - val_loss: 2.0763 - val_accuracy: 0.4199\n",
            "Epoch 62/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1766 - accuracy: 0.3927 - val_loss: 2.0703 - val_accuracy: 0.4227\n",
            "Epoch 63/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1733 - accuracy: 0.3946 - val_loss: 2.0598 - val_accuracy: 0.4180\n",
            "Epoch 64/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1649 - accuracy: 0.3939 - val_loss: 2.0486 - val_accuracy: 0.4219\n",
            "Epoch 65/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1569 - accuracy: 0.3959 - val_loss: 2.0459 - val_accuracy: 0.4298\n",
            "Epoch 66/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1628 - accuracy: 0.3987 - val_loss: 2.0625 - val_accuracy: 0.4246\n",
            "Epoch 67/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1442 - accuracy: 0.4005 - val_loss: 2.0279 - val_accuracy: 0.4274\n",
            "Epoch 68/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1416 - accuracy: 0.3996 - val_loss: 2.0314 - val_accuracy: 0.4310\n",
            "Epoch 69/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1326 - accuracy: 0.4018 - val_loss: 2.0144 - val_accuracy: 0.4285\n",
            "Epoch 70/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1269 - accuracy: 0.4027 - val_loss: 2.0054 - val_accuracy: 0.4349\n",
            "Epoch 71/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1212 - accuracy: 0.4040 - val_loss: 2.0060 - val_accuracy: 0.4377\n",
            "Epoch 72/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1164 - accuracy: 0.4081 - val_loss: 2.0050 - val_accuracy: 0.4406\n",
            "Epoch 73/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.1079 - accuracy: 0.4074 - val_loss: 1.9777 - val_accuracy: 0.4405\n",
            "Epoch 74/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0949 - accuracy: 0.4097 - val_loss: 1.9905 - val_accuracy: 0.4403\n",
            "Epoch 75/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0945 - accuracy: 0.4099 - val_loss: 1.9847 - val_accuracy: 0.4412\n",
            "Epoch 76/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0935 - accuracy: 0.4099 - val_loss: 1.9467 - val_accuracy: 0.4567\n",
            "Epoch 77/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0826 - accuracy: 0.4123 - val_loss: 1.9243 - val_accuracy: 0.4543\n",
            "Epoch 78/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0749 - accuracy: 0.4128 - val_loss: 1.9227 - val_accuracy: 0.4574\n",
            "Epoch 79/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0689 - accuracy: 0.4150 - val_loss: 1.9301 - val_accuracy: 0.4581\n",
            "Epoch 80/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0571 - accuracy: 0.4185 - val_loss: 1.9201 - val_accuracy: 0.4611\n",
            "Epoch 81/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0521 - accuracy: 0.4189 - val_loss: 1.9093 - val_accuracy: 0.4652\n",
            "Epoch 82/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0497 - accuracy: 0.4192 - val_loss: 1.9053 - val_accuracy: 0.4619\n",
            "Epoch 83/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0513 - accuracy: 0.4213 - val_loss: 1.9142 - val_accuracy: 0.4606\n",
            "Epoch 84/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0427 - accuracy: 0.4229 - val_loss: 1.9120 - val_accuracy: 0.4583\n",
            "Epoch 85/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0352 - accuracy: 0.4236 - val_loss: 1.8793 - val_accuracy: 0.4692\n",
            "Epoch 86/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 2.0246 - accuracy: 0.4276 - val_loss: 1.8733 - val_accuracy: 0.4662\n",
            "Epoch 87/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 2.0246 - accuracy: 0.4282 - val_loss: 1.8524 - val_accuracy: 0.4761\n",
            "Epoch 88/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0150 - accuracy: 0.4275 - val_loss: 1.8610 - val_accuracy: 0.4757\n",
            "Epoch 89/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0158 - accuracy: 0.4282 - val_loss: 1.8523 - val_accuracy: 0.4756\n",
            "Epoch 90/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 2.0018 - accuracy: 0.4320 - val_loss: 1.8125 - val_accuracy: 0.4973\n",
            "Epoch 91/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9930 - accuracy: 0.4339 - val_loss: 1.8555 - val_accuracy: 0.4737\n",
            "Epoch 92/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 1.9947 - accuracy: 0.4329 - val_loss: 1.8110 - val_accuracy: 0.4910\n",
            "Epoch 93/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 1.9814 - accuracy: 0.4326 - val_loss: 1.8232 - val_accuracy: 0.4854\n",
            "Epoch 94/200\n",
            "12/12 [==============================] - 22s 2s/step - loss: 1.9843 - accuracy: 0.4344 - val_loss: 1.8140 - val_accuracy: 0.4904\n",
            "Epoch 95/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9833 - accuracy: 0.4358 - val_loss: 1.7992 - val_accuracy: 0.4923\n",
            "Epoch 96/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9728 - accuracy: 0.4391 - val_loss: 1.7796 - val_accuracy: 0.5009\n",
            "Epoch 97/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9677 - accuracy: 0.4401 - val_loss: 1.7828 - val_accuracy: 0.4966\n",
            "Epoch 98/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9628 - accuracy: 0.4428 - val_loss: 1.7782 - val_accuracy: 0.5071\n",
            "Epoch 99/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9518 - accuracy: 0.4456 - val_loss: 1.7588 - val_accuracy: 0.5056\n",
            "Epoch 100/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9546 - accuracy: 0.4437 - val_loss: 1.7303 - val_accuracy: 0.5152\n",
            "Epoch 101/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9500 - accuracy: 0.4419 - val_loss: 1.7716 - val_accuracy: 0.4993\n",
            "Epoch 102/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9493 - accuracy: 0.4443 - val_loss: 1.7548 - val_accuracy: 0.5130\n",
            "Epoch 103/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9348 - accuracy: 0.4473 - val_loss: 1.7652 - val_accuracy: 0.5049\n",
            "Epoch 104/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9361 - accuracy: 0.4464 - val_loss: 1.7240 - val_accuracy: 0.5165\n",
            "Epoch 105/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.9255 - accuracy: 0.4501 - val_loss: 1.7404 - val_accuracy: 0.5094\n",
            "Epoch 106/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9192 - accuracy: 0.4518 - val_loss: 1.7041 - val_accuracy: 0.5260\n",
            "Epoch 107/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9106 - accuracy: 0.4544 - val_loss: 1.7018 - val_accuracy: 0.5216\n",
            "Epoch 108/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9156 - accuracy: 0.4536 - val_loss: 1.7112 - val_accuracy: 0.5191\n",
            "Epoch 109/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.9061 - accuracy: 0.4543 - val_loss: 1.6882 - val_accuracy: 0.5266\n",
            "Epoch 110/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.9041 - accuracy: 0.4534 - val_loss: 1.6945 - val_accuracy: 0.5231\n",
            "Epoch 111/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8948 - accuracy: 0.4549 - val_loss: 1.6898 - val_accuracy: 0.5267\n",
            "Epoch 112/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8933 - accuracy: 0.4562 - val_loss: 1.6608 - val_accuracy: 0.5387\n",
            "Epoch 113/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8944 - accuracy: 0.4590 - val_loss: 1.6810 - val_accuracy: 0.5288\n",
            "Epoch 114/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8850 - accuracy: 0.4605 - val_loss: 1.6763 - val_accuracy: 0.5281\n",
            "Epoch 115/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8818 - accuracy: 0.4608 - val_loss: 1.6399 - val_accuracy: 0.5402\n",
            "Epoch 116/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8675 - accuracy: 0.4668 - val_loss: 1.6595 - val_accuracy: 0.5377\n",
            "Epoch 117/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8720 - accuracy: 0.4612 - val_loss: 1.6244 - val_accuracy: 0.5467\n",
            "Epoch 118/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.8747 - accuracy: 0.4636 - val_loss: 1.6254 - val_accuracy: 0.5472\n",
            "Epoch 119/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8621 - accuracy: 0.4662 - val_loss: 1.6228 - val_accuracy: 0.5507\n",
            "Epoch 120/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8438 - accuracy: 0.4704 - val_loss: 1.6045 - val_accuracy: 0.5564\n",
            "Epoch 121/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8497 - accuracy: 0.4705 - val_loss: 1.6076 - val_accuracy: 0.5521\n",
            "Epoch 122/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8463 - accuracy: 0.4683 - val_loss: 1.5911 - val_accuracy: 0.5621\n",
            "Epoch 123/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8468 - accuracy: 0.4700 - val_loss: 1.5835 - val_accuracy: 0.5594\n",
            "Epoch 124/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8375 - accuracy: 0.4749 - val_loss: 1.5933 - val_accuracy: 0.5508\n",
            "Epoch 125/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.8336 - accuracy: 0.4740 - val_loss: 1.5970 - val_accuracy: 0.5533\n",
            "Epoch 126/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8378 - accuracy: 0.4730 - val_loss: 1.5717 - val_accuracy: 0.5642\n",
            "Epoch 127/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8262 - accuracy: 0.4743 - val_loss: 1.5731 - val_accuracy: 0.5575\n",
            "Epoch 128/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8232 - accuracy: 0.4750 - val_loss: 1.5919 - val_accuracy: 0.5558\n",
            "Epoch 129/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8189 - accuracy: 0.4760 - val_loss: 1.5652 - val_accuracy: 0.5576\n",
            "Epoch 130/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.8201 - accuracy: 0.4773 - val_loss: 1.5748 - val_accuracy: 0.5622\n",
            "Epoch 131/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8150 - accuracy: 0.4779 - val_loss: 1.5359 - val_accuracy: 0.5746\n",
            "Epoch 132/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.8033 - accuracy: 0.4792 - val_loss: 1.5471 - val_accuracy: 0.5714\n",
            "Epoch 133/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8055 - accuracy: 0.4802 - val_loss: 1.5640 - val_accuracy: 0.5683\n",
            "Epoch 134/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.7983 - accuracy: 0.4804 - val_loss: 1.5324 - val_accuracy: 0.5768\n",
            "Epoch 135/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8071 - accuracy: 0.4788 - val_loss: 1.4861 - val_accuracy: 0.5830\n",
            "Epoch 136/200\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.7979 - accuracy: 0.4829 - val_loss: 1.5351 - val_accuracy: 0.5716\n",
            "Epoch 137/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.7939 - accuracy: 0.4859 - val_loss: 1.5302 - val_accuracy: 0.5733\n",
            "Epoch 138/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.7883 - accuracy: 0.4827 - val_loss: 1.5407 - val_accuracy: 0.5740\n",
            "Epoch 139/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.7975 - accuracy: 0.4837 - val_loss: 1.5186 - val_accuracy: 0.5768\n",
            "Epoch 140/200\n",
            "12/12 [==============================] - 20s 2s/step - loss: 1.7837 - accuracy: 0.4860 - val_loss: 1.5212 - val_accuracy: 0.5787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-16 18:34:11,759 : MainThread : INFO : Saving model history to model_history.csv\n",
            "2022-03-16 18:34:11,767 : MainThread : INFO : Saving model to /content/checkpoints/synthetic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in generate_text(config, line_validator=None, num_lines=1000):\n",
        "\n",
        "   print(line.text)"
      ],
      "metadata": {
        "id": "O82PVWngmogX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_record(line):\n",
        "\n",
        "   rec = line.split(\", \")\n",
        "\n",
        "   if len(rec) == 24:\n",
        "       float(rec[23])\n",
        "       float(rec[22])\n",
        "       float(rec[21])\n",
        "       float(rec[20])\n",
        "       float(rec[19])\n",
        "       float(rec[18])\n",
        "       float(rec[17])\n",
        "       float(rec[16])\n",
        "       float(rec[15])\n",
        "       float(rec[14])\n",
        "       float(rec[13])\n",
        "       float(rec[12])\n",
        "       float(rec[11])\n",
        "       float(rec[10])\n",
        "       float(rec[9])\n",
        "       float(rec[8])\n",
        "       float(rec[7])\n",
        "       float(rec[6])\n",
        "       float(rec[5])\n",
        "       float(rec[4])\n",
        "       float(rec[3])\n",
        "       float(rec[2])\n",
        "       int(rec[0])\n",
        "\n",
        "   else:\n",
        "\n",
        "       pass"
      ],
      "metadata": {
        "id": "57TJKl15oHuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = generate_text(config, line_validator=validate_record, num_lines=1000)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra8DtIrerUKq",
        "outputId": "18212f64-e467-41b0-e335-122dd4281987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object generate_text at 0x7f9023e33ad0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "temp = \"\"\n",
        "# for line in data:\n",
        "#   print(line.text)\n",
        "with open('/content/sample_data/sample.txt', 'w') as the_file:\n",
        "    for line in data:\n",
        "      temp = line.text.split(',')\n",
        "      if len(temp) == 26 :\n",
        "        the_file.write(line.text + '\\n')\n",
        "      elif len(temp) > 26:\n",
        "        del temp[26:]\n",
        "        tempstr = \",\".join(temp)\n",
        "        the_file.write(tempstr + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38xUdRq4refr",
        "outputId": "b05694d6-2f79-4ecd-ff96-9ba8aeefa356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-16 20:19:24,554 : MainThread : INFO : Loading tokenizer from: m.model\n",
            "2022-03-16 20:19:24,565 : MainThread : INFO : Tokenizer model vocabulary size: 1371 tokens\n",
            "2022-03-16 20:19:24,567 : MainThread : INFO : Mapping first line of training data\n",
            "\n",
            "'18.66<d>18.82<d>18.05<d>18.25<d>18.69<d>19.5<d>21.03<d>20.67<d>20.25<d>19.45<d>17.33<d>16.53<d>15.73<d>15.2<d>14.17<d>13.89<d>14.71<d>16.47<d>19.01<d>18.69<d>18.47<d>16.92<d>15.1<d>14.79<n>'\n",
            " ---- sample tokens mapped to pieces ---- > \n",
            "▁, 18.6, 6, <d>, 18.8, 2, <d>, 1, 8., 05, <d>, 1, 8., 2, 5, <d>, 18., 6, 9, <d>, 1, 9., 5, <d>, 21, ., 03, <d>, 20., 67, <d>, 2, 0, ., 2, 5, <d>, 19.4, 5, <d>, 1, 7., 33, <d>, 16, ., 53, <d>, 15.7, 3, <d>, 15., 2, <d>, 14, ., 1, 7, <d>, 13, ., 8, 9, <d>, 14., 71, <d>, 1, 6, ., 4, 7, <d>, 19., 01, <d>, 1, 8, ., 69, <d>, 18.4, 7, <d>, 1, 6, .9, 2, <d>, 1, 5.1, <d>, 14.7, 9, <n>\n",
            "\n",
            "2022-03-16 20:19:24,573 : MainThread : INFO : Mapping first line of training data\n",
            "\n",
            "'18.66<d>18.82<d>18.05<d>18.25<d>18.69<d>19.5<d>21.03<d>20.67<d>20.25<d>19.45<d>17.33<d>16.53<d>15.73<d>15.2<d>14.17<d>13.89<d>14.71<d>16.47<d>19.01<d>18.69<d>18.47<d>16.92<d>15.1<d>14.79<n>'\n",
            " ---- sample tokens mapped to int ---- > \n",
            "694, 10, 4, 113, 6, 4, 123, 11, 4, 238, 11, 4, 91, 13, 4, 102, 4, 107, 8, 4, 129, 12, 4, 242, 11, 4, 146, 11, 4, 276, 8, 4, 127, 8, 4, 207, 8, 4, 385, 4, 45, 28, 4, 301, 13, 4, 250, 7, 4, 202, 12, 4, 121, 7, 4, 91, 13, 4, 178, 12, 4, 159, 6, 4, 337, 4, 250, 13, 3\n",
            "\n"
          ]
        }
      ]
    }
  ]
}